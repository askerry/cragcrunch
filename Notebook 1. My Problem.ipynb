{
 "metadata": {
  "name": "",
  "signature": "sha256:01eefbb64a9061be7544d5d29f5b2ef6d12609d406be42afe41b32f2715954d6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Day 1 of Insight Data Science: What is my problem?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The biggest perk of the Insight program is that I get to spend 3-4 straight weeks working on a data-related project of my choosing. I not only get to spend these weeks surrounded by smart, interesting people to learn from, but I also get to hack away on whatever problem I want!?! Awesome.\n",
      "\n",
      "So, what is my problem? The first few days at Insight were devoted to this question.\n",
      "\n",
      "Identifying the problem I want to solve, and the questions I need to answer to solve that problem, is one of the biggest challenges in data science. It won\u2019t matter how much data I have, how effectively I sanitize it, or whether I use the right machine learning algorithm-- if I'm not asking the right questions, or tackling the right problem, I am unlikely to achieve substantial gains from my data science project.\n",
      "\n",
      "For this particular project, there are two types of factors to consider. 1) I want to find a project that I\u2019m passionate about, and for which there are insights or benefits to be gained from an extensive data investigation. 2) I want to choose a project that will challenge me, push me to expand my skillset, and provide a vehicle for communicating these skills to others (i.e. companies I want to work for).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. What problem do I want to solve?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I love rock climbing. If I\u2019m not sitting at my computer, chances are I am some number of feet up a rock climbing wall. It turns out, rock climbers are often data nerds. We like to document details about rock climbs all over the world, we tend to know which routes we\u2019ve climbed and when, and we tend to post this information on the web. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The problem:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a rock climber, there is nothing more exciting than planning a trip to a new climbing area. However, a given climbing area or national park often contains hundres or thousands of individual rock routes, and climbers will only tackle a handful of the routes on any given trip. Thus, climbers are often looking to find new climbing routes that they will enjoy and that will be appropriate for their skill level.\n",
      "\n",
      "The primary goal of CragCrunch is personalization. Every climber is [unique](http://climbingnarc.com/2012/01/defining-your-style/) and comes to the crag with their own skills, preferences, and goals. Similarly, every climb is different (e.g. different types of [holds](http://climbing.about.com/od/RockClimbingTechnique/tp/Nine-Basic-Types-Of-Climbing-Handholds.htm) and [faces](http://climbing.about.com/od/cliimbingtechniques/a/3RockFaces.htm)) and demands its own blend of mental and physical skills. CragCrunch aims to learn about its individual users to create a personalized system for finding climbs that are right for YOU. The key feature of this system is a recommendation engine that makes personalized suggestions based on a user-specific preference model. For users who have not built up an extensive climbing history, CragCrunch also provides for each climb suggestions of similar climbs. So look up a route you love and CragCrunch will suggest other climbs to add to your tick list. The climbing community helped to build this data source, so I want us to have the freedom to interact with the data to meet our individual goals and needs."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. What do I want to learn as a data scientist?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data science skills in:\n",
      "- statistics/machine learning\n",
      "- programming\n",
      "- data visualization\n",
      "- scientific hypothesis testing, analytic thinking\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For me, #4 has been the bread and butter of my last ~8 years. I have some foundation in #1-#3 that I acquired as needed to answer scientific questions, but I have lots to learn to be able to tackle problems in industry. Here are a few of my learning goals for Insight, based on what I see as some of the largest disconnects between the kind of data analysis I\u2019ve done, and the kind of powers I\u2019ll need to be a successful data scientist:\n",
      "- Data wrangling: my fMRI data are images. I know exactly what they will look like and what kind of values they can take. there are some cleaning/preprocessing steps but they are fairly routine\n",
      "- Data scaling: neuroscience data is not big data. I don\u2019t know or care exactly how much data constitutes \"big data\", but I know that we are far away from industry levels.\n",
      "- Rapid, iterative data exploration: we often plan our analysis ahead of time, and stick to the plan to avoid over-fitting with overly flexible analysis plans. I want to be able to quickly load up a dataset and get insights.\n",
      "- Prediction and model evaluation: Data scientists and scientists are often asking fundamentally different questions\u2026 scientists are trying to characterize a system and make causal inferences whereas data scientists are more frequently trying to make useful predictions.\n",
      "- Using models in production: we get an \u201canswer\u201d, summarize it/visualize it, and present it in a paper, rather the using the statistical models to support an online service or product.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Project Proposal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I want to build a platform for discovering new rock climbing routes, including a recommendation engine that provides personalized suggestions based on user history. How can I do this? Many climbers climb the same routes, and climbers often travel to different areas. Luckily, many climbers also record their climbing history on a website called www.mountainproject.com. This website also logs objective variables (such as rock type, route length, and elevation) and more unstructured content (user-generated descriptions, comments) that could provide useful signals for identifying routes that are a good fit for a given individual. If I can harness this data (objective attributes, user-generated content, logs of which climbers have completed which routes, and whether they enjoyed them), I can build systems for characterizing the similarity between different climbs, and for providing personalized climbing recommendations.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learning Goals\u2192 Project Components\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "1. Data wrangling, cleaning --> web scraping and extensive wrangling of user-entered data from web resource\n",
      "1. Data scaling --> transforming scraped data into structured schemas that can be queried efficiently in SQL, use of dimensionality reduction (feature selection), using pre-computation and parallelization to speed up processing\n",
      "1. Rapid, iterative data exploration --> when scraping a messy data source, need to do lots of quick investigations to assess data quality and figure out what preprocessing/cleaning steps are required\n",
      "1. Prediction and model evaluation--> will build models for individual users to predict their climbing preferences, evaluate model on untrained data\n",
      "1. Using models in production -->user-specific models will be loaded online to generate rankings of candidate climbs within user specified regions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tools"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "My analyses relied heavily on the following python libraries:\n",
      "\n",
      "1. [Scrapy](http://scrapy.org/) for web scraping\n",
      "2. [Sqlalchemy](http://www.sqlalchemy.org/) for converting scraped data classes into a set of relational database schemas (MySQL)\n",
      "3. [Pandas](http://pandas.pydata.org/) for online data representation and transformation\n",
      "4. [Scipy](http://www.scipy.org/scipylib/index.html) and [Statsmodels](http://statsmodels.sourceforge.net/) for inferential statistics\n",
      "5. [Sci-kit learn](http://scikit-learn.org/stable/) for building models (constructing cross-validation procedures, performing feature selection, fitting model parameters, testing trained models)\n",
      "6. [Matplotlib](http://matplotlib.org/) and [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) for visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}