{
 "metadata": {
  "name": "",
  "signature": "sha256:2242ab99a9adf1d3461b267682ef3274b5b427ee7f6773897a4c0cb1e28a2932"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing scraped data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A fair amount of data cleaning was performed online during the scraping process. However, the data stored in the initial database is still rather messy and there is work to be done  post acquisition. Here, I implement further cleaning/wrangling and reduction to get the data in shape for modeling and visualization. In addition to basic cleaning, I perform a number of preprocessing steps to compute additional variables of interest (e.g. compute for each climb the delta between each individual users rating and the rating of all other users, get word counts for a set of a priori domain relevant terms, etc.)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#general\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "np.random.RandomState(100)\n",
      "from sqlalchemy import create_engine\n",
      "import MySQLdb\n",
      "import os\n",
      "import sys\n",
      "sys.setrecursionlimit(3000)\n",
      "\n",
      "#project specific code\n",
      "sys.path.append('mpscraper')\n",
      "from mpscraper.cfgdb import cfg\n",
      "sys.path.append('antools')\n",
      "import antools.random as rd\n",
      "import antools.utilities as util\n",
      "import antools.clean as clean\n",
      "import antools.reduction as red\n",
      "import antools.miscdf as miscdf\n",
      "import antools.climbingcalcs as ccc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir=os.getcwd()\n",
      "while 'Projects' in rootdir:\n",
      "    rootdir=os.path.dirname(rootdir)\n",
      "rootdir=os.path.join(rootdir, 'Projects','cragcrunch')\n",
      "dropfulls=True #if true, drop the full dataframes once we split into train and test (to save RAM)\n",
      "writedb=True #write dfs to sql database\n",
      "chunksize=1000 #chunk size when writing out large dataframes to sql\n",
      "terms=rd.rockterms+rd.holdterms+rd.descriptors+rd.easeterms+rd.safetyterms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load in raw scraped data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "con=MySQLdb.connect(user=cfg.user, passwd=cfg.passwd, db=cfg.dbname, host=cfg.host, charset=cfg.charset, use_unicode=cfg.charset)\n",
      "full_climbdf = pd.read_sql(\"SELECT * from Climb\", con)\n",
      "full_climbdf=full_climbdf[['name']+[el for el in full_climbdf.columns.tolist() if el!='name']] #moving name first\n",
      "full_areadf = pd.read_sql(\"SELECT * from Area\", con)\n",
      "full_climberdf = pd.read_sql(\"SELECT * from Climber\", con)\n",
      "full_tickdf = pd.read_sql(\"SELECT * from Ticks\", con)\n",
      "full_commentdf = pd.read_sql(\"SELECT * from Comments\", con)\n",
      "full_gradedf = pd.read_sql(\"SELECT * from Grades\", con)\n",
      "full_stardf = pd.read_sql(\"SELECT * from Stars\", con)\n",
      "full_tododf = pd.read_sql(\"SELECT * from ToDos\", con)\n",
      "print \"data loaded\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data loaded\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clean up individual attributes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "cleandf does some very bare bones cleaning... makes sure columns are of the right datatype, strips empty spaces from ends of strings, cleans up missing values, etc.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf=util.cleandf(full_climbdf)\n",
      "full_areadf=util.cleandf(full_areadf) \n",
      "full_climberdf=util.cleandf(full_climberdf) \n",
      "full_tickdf=util.cleandf(full_tickdf) \n",
      "full_commentdf=util.cleandf(full_commentdf) \n",
      "full_gradedf=util.cleandf(full_gradedf) \n",
      "full_stardf=util.cleandf(full_stardf) \n",
      "full_tododf=util.cleandf(full_tododf) \n",
      "print \"performed dataframe initial cleaning\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed dataframe initial cleaning\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climb styles that fall outside scope of the project"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we are focusing on rock climbing and will drop alpine/ice climbing data from the dataset\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropstyles(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"dropped types of climbs we don't care about\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped types of climbs we don't care about\n",
        "starting with 121849, reducing to 106561\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas in the USA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf, full_areadf=red.limittoUSA(full_climbdf, full_areadf)\n",
      "print \"limited to USA\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))\n",
      "print \"starting with %s, reducing to %s\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "limited to USA\n",
        "starting with 26703, reducing to 21106\n",
        "starting with 106561, reducing to 98341\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Align location information and drop climbs that are missing location info"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf=pd.merge(full_climbdf, full_areadf[['areaid','region']], left_on='area', right_on='areaid', how='inner')\n",
      "full_climbdf=full_climbdf.rename(columns={'region_y':'region'})\n",
      "del full_climbdf['region_x']\n",
      "print \"added regions to climbs and dropped climbs missing areas\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "added regions to climbs and dropped climbs missing areas\n",
        "starting with 98341, reducing to 92314\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climbs for which we don't have grade information\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropungraded(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting with 92314, reducing to 92314\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Removing duplicates, fixing missing values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.dedupsandmissing(full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"performed deduping, filled in missing values\"\n",
      "print \"starting with %s, reducing to %s\" %(j, len(full_climbdf))\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed deduping, filled in missing values\n",
        "starting with 92314, reducing to 92314\n",
        "starting with 21106, reducing to 21005\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Climber x Climb Matrix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "make single df of all climberxclimb interactions (of any kind: tick, star, grade, comment), on the assumption that any of these indicate an attempt at the climb. (i.e. 1 or 0 based on whether climber interacted with climb in any capacity)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_hitsdf=pd.concat([full_tickdf[['climb','climber', 'urlname']],full_tododf[['climb','climber','urlname']],full_commentdf[['climb','climber','urlname']],full_gradedf[['climb','climber','urlname']]])\n",
      "full_hitsdf=full_hitsdf.drop_duplicates()\n",
      "full_hitsdf=full_hitsdf.loc[~np.isnan(full_hitsdf.climber.values)]\n",
      "full_hitsdf.index=range(len(full_hitsdf))\n",
      "full_hitsdf['hitsid']=full_hitsdf.index.values\n",
      "print \"created full climber x climb matrix\"\n",
      "print \"%s hits\" %len(full_hitsdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "created full climber x climb matrix\n",
        "159807 hits\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Misc fixes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fix up some climber data errors\n",
      "full_climberdf=clean.fixclimbers(full_climberdf, full_hitsdf)\n",
      "\"fixed duped climbers\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "'fixed duped climbers'"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reindex everything so that id is index\n",
      "%autoreload\n",
      "full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.reindexall(full_hitsdf,full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"reindexed dataframes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reindexed dataframes\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "goofed up when extracting data and thought we were in a 1-5 system. actually in 0-4 where zero is \"danger\"/\"bomb\" rating"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#random cleanup hacks\n",
      "full_stardf.starsscore=full_stardf.starsscore-1\n",
      "full_climberdf.loc[full_climberdf['age']>120, 'age']=np.nan\n",
      "print \"performed random cleanup hacks\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed random cleanup hacks\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convert grade to a linear scale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we may want to compute differences between grades (e.g. across users) and therefore need a metric scale for the grade data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf['numerizedgrade']=full_climbdf['grade'].apply(clean.numerizegrades, gradelists=[rd.grades, rd.bouldergrades])\n",
      "full_climbdf['numgrade']=full_climbdf['grade'].apply(clean.splitgrade, output='num')\n",
      "full_climbdf['lettergrade']=full_climbdf['grade'].apply(clean.splitgrade, output='letter')\n",
      "print \"redefined grading\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "redefined grading\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find main parks/areas for climbs and climbers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "states, stateids, statedict, mainareadf, xa, xcl=ccc.getstatesandmainareas(full_areadf, full_climbdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified main areas/parks for subareas\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "because we dropped non-USA and certain forms of climbers, there are users for which we have no climbing history. drop them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climberdf)\n",
      "full_climberdf=full_climberdf[full_climberdf['climberid'].isin(full_hitsdf.climber.values)]\n",
      "print \"dropping climbers for which we have no climbing history\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climberdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping climbers for which we have no climbing history\n",
        "starting with 5685, reducing to 1535\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm going to assume that the park you climb in most is your home crag/\"mainarea\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "x=ccc.getclimberareas(full_hitsdf, full_climbdf, full_climberdf) #note this uses whole dataset, shouldn't be part of any training/testing\n",
      "print \"identified climber mainareas\"   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified climber mainareas\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getregion(mid, areadf):\n",
      "    return areadf[areadf['areaid']==mid].region.values[0]\n",
      "full_climberdf['region']=full_climberdf['mainarea'].apply(getregion, areadf=full_areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract counts for a priori terms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "extract word counts for a priori terms (e.g. describing rock types, hold types, face angle, etc) from comments and descriptions\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"merging climb comments\"\n",
      "full_climbdf=miscdf.mergeclimbcomment(full_commentdf, full_climbdf)\n",
      "print \"making descripdf\"\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['description']) #'commentsmerged'\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['commentsmerged'])\n",
      "print \"finished descripdf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging climb comments\n",
        "making descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "finished descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Deal with star rating data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf=clean.fixstars(full_stardf, full_climbdf)\n",
      "print \"fixed stars\"\n",
      "full_climbdf=miscdf.combinestars(full_climbdf)\n",
      "print \"combined stars\"\n",
      "full_climbdf['roundedstars']=full_climbdf['avgstars'].apply(np.round) \n",
      "full_stardf=ccc.computerelativestar(full_stardf,full_climbdf)\n",
      "print \"computed relative stars\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fixed stars\n",
        "combined stars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:245: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "  self.obj[key] = np.nan\n",
        "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:415: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "  self.obj[item] = s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "computed relative stars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "morecols=full_climbdf['climbid'].apply(ccc.getratingcounts, sdf=full_stardf)\n",
      "full_climbdf['starcounts']=[x[0] for x in morecols.values]\n",
      "full_climbdf['starstd']=[x[1] for x in morecols.values]\n",
      "print \"counted number of raters for each avg rating score\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "counted number of raters for each avg rating score\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "singleids=full_climbdf[full_climbdf.starcounts<=1].climbid.values\n",
      "i=len(full_stardf)\n",
      "full_stardf=full_stardf[~full_stardf['climb'].isin(singleids)]\n",
      "print \"dropping from stardf %s climbs only rated by one climber :(\" %len(singleids)\n",
      "print \"reduced from %s to %s in star df\" %(i, len(full_stardf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping from stardf 63809 climbs only rated by one climber :(\n",
        "reduced from 202295 to 179436 in star df\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#users might differ in their distribution of grades, so let's get the mean for each user. we'll do this separately for each rating, excluding the current rating \n",
      "#full_stardf['user_avg']=full_stardf.apply(lambda x:getavg(x['starid'], x['climber'], sdf=full_stardf), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We at some point may want to use the average rating for a climb as a prior or fallback prediction for an individual climber. but the avg ratings stored in full_climbdf include data from the climber we are trying to predict, which is circular. for each climber-climb pair, let's compute the avg and std of the ratings for all climbers excluding the target."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "othercols=full_stardf.apply(lambda x: ccc.getnonuserstar(x['climb'], x['climber'], sdf=full_stardf[full_stardf['climb']==x['climb']]), axis=1)\n",
      "full_stardf['other_avg']=[x[0] for x in othercols.values]\n",
      "full_stardf['other_std']=[x[1] for x in othercols.values]\n",
      "full_stardf.loc[np.isnan(full_stardf['other_avg']), 'other_avg']=full_climbdf.avgstars.mean()\n",
      "print \"got average rating for each climb-user pair, excluding the rating given by that climber\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "got average rating for each climb-user pair, excluding the rating given by that climber\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get relative grade"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Does the climber find this climb harder than other people who climbed it? This could be informative as it suggests that this climbs attributes are possible weaknesses for the climber..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_gradedf=ccc.computerelativegrades(full_climbdf, full_gradedf)\n",
      "print \"computed relative grades\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "computed relative grades\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get grade range and average for each climber"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climberdf['numhits']=full_climberdf['climberid'].apply(ccc.getnumhits, hdf=full_hitsdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ccols=full_climberdf['climberid'].apply(ccc.getclimberdata, hdf=full_hitsdf, cdf=full_climbdf)\n",
      "full_climberdf['g_min']=[x[0] for x in ccols.values]\n",
      "full_climberdf['g_max']=[x[1] for x in ccols.values]\n",
      "full_climberdf['g_median']=[x[2] for x in ccols.values]\n",
      "print \"got some climber grade stats (min, max, median)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "got some climber grade stats (min, max, median)\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Deal with variability in grading standards across regions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Grading standards can differ across regions. Older trad areas tend to have stiff grades (meaning the climbs are relatively difficult given the grade), whereas newer areas might give the same climb a harder grade. it would be great to be able to take this into account when suggesting climbs well suited to the users climbing level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##NVM this is actually really hard. regionds differ in stiffness but also in difficulty (e.g. some areas really have only hard climbs, others just grade soft). I'll hold off.\n",
      "#print \"computing grade variability\"\n",
      "#climbdf=computegradevariability(climbdf, gradedf)\n",
      "#climbdf=computeclimbstiffness(climbdf, gradedf, climberdf)\n",
      "#print \"finished grade stiffness\"\n",
      "#areadf=computeareastiffness(climbdf, areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#submittercounts=summarizesubmitters(climbdf, climberdf, hitsdf) #note this uses whole dataset, shouldn't be part of any training/testing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas for which we have some user data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we don't have any data of users climbing a climb, let's ignore it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf=full_climbdf[full_climbdf['climbid'].isin(full_hitsdf.climb.values)]\n",
      "areas=list(full_climbdf.area.unique())+list(full_areadf.area.unique())\n",
      "full_areadf=full_areadf[full_areadf['areaid'].isin(areas)]\n",
      "print \"dropped climbs with no user data\"\n",
      "print \"starting with %s areas, reducing to %s areas\" %(i, len(full_areadf))\n",
      "print \"starting with %s climbs, reducing to %s climbs\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped climbs with no user data\n",
        "starting with 21005 areas, reducing to 11918 areas\n",
        "starting with 92314 climbs, reducing to 41473 climbs\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "For now let's limit the product to climbs in California and New Hampshire"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOTE: I'll do exploratory analyses (visualizing data, playing around with different algorithms and parameters) on the New Hampshire climbs, since I have high familiarity with the area and can use my domain knowledge to sanity check my procedures and for qualitative validation of various approaches, in addition to quantititive validation (performance on left out CV folds). Then I'll perform my final analysis with training and quantitative validation on the California data. Splitting my analysis into an exploratory stage and a final analysis stage (with separate datasets) allows me to play around with a variety of analytic techniques without overfitting when choosing models/hyper parameters. I like to think of all analysis decisions as hyper parameters. Thus, making decisions like choosing a model (e.g. svm vs. logistic regression vs. random forests) because it performs best on your validation data can overestimate your performance in the same way that fitting individual model parameters to your test data would."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_climbdf=full_climbdf[full_climbdf['region'].isin(['California','New Hampshire', 'World'])]\n",
      "full_areadf=full_areadf[full_areadf['region'].isin(['California','New Hampshire', 'World'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)\n",
      "full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf, mainareadf=util.renameindices(full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf, mainareadf)\n",
      "full_hitsdf=full_hitsdf[full_hitsdf['climber'].isin(full_climberdf.climberid.unique())]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%s climbs\" %len(full_climbdf)\n",
      "print \"%s climbers\" %len(full_climberdf)\n",
      "print \"%s areas\" %len(full_areadf)\n",
      "print \"%s hits\" %len(full_hitsdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9600 climbs\n",
        "1535 climbers\n",
        "3315 areas\n",
        "4563 hits\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Write preprocessed data to database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if writedb:\n",
      "    #save prepped data to sql\n",
      "    engine = create_engine('mysql://%s@%s/%s?charset=%s&use_unicode=%s&passwd=%s' %(cfg.user, cfg.host, cfg.dbname, cfg.charset, cfg.use_unicode, cfg.passwd), pool_recycle=3600)\n",
      "    full_areadf.to_sql('area_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_climberdf.to_sql('climber_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tickdf.to_sql('ticks_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_commentdf.to_sql('comments_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_gradedf.to_sql('grades_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_stardf.to_sql('stars_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tododf.to_sql('todos_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_hitsdf.to_sql('hits_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_climbdf.to_sql('climb_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    #regioninfo={'regions':regions, 'regionids':regionids, 'regiondict':regiondict}\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'regioninfo.pkl'), [regioninfo])\n",
      "    util.pickletheseobjects(os.path.join(rootdir, 'data', 'terms.pkl'),[terms])\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'vterms.pkl'),[valenceterms])\n",
      "    mainareadf.to_sql('mainarea_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    #climberxareadf.to_sql('climberxareadf_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    #submittercounts.to_sql('submittercounts_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    print \"wrote to db\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wrote to db\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}