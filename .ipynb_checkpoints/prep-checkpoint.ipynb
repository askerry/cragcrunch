{
 "metadata": {
  "name": "",
  "signature": "sha256:7a0a2feee96214a9f0c62dd7080777faff046821c7774bd799298acf4fb84b0b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "#basic\n",
      "import pandas as pd\n",
      "pd.options.mode.chained_assignment = 'warn'  # default='warn', None, 'raise'\n",
      "#pd.options.display.memory_usage = True\n",
      "import numpy as np\n",
      "np.random.RandomState(100)\n",
      "import MySQLdb\n",
      "from sqlalchemy import create_engine\n",
      "import os\n",
      "import sys\n",
      "sys.setrecursionlimit(3000)\n",
      "from joblib import Parallel, delayed  \n",
      "import multiprocessing\n",
      "num_cores = multiprocessing.cpu_count()\n",
      "print \"%s cores available for parallel processing\" % num_cores\n",
      "import sys, os\n",
      "\n",
      "\n",
      "#interaction\n",
      "from IPython.html import widgets # Widget definitions\n",
      "from IPython.display import display # Used to display widgets in the notebook\n",
      "\n",
      "#specific\n",
      "sys.path.append('mpscraper')\n",
      "sys.path.append('analysis')\n",
      "from mpscraper.cfgdb import cfg\n",
      "import analysis.utilities as util\n",
      "from analysis.analyze import modeldict\n",
      "from analysis.domainvariables import states, grades, rawgrades, bouldergrades, holdterms, rockterms, descriptors, easeterms, safetyterms\n",
      "#viz\n",
      "import seaborn as sns\n",
      "sns.set_style('white')\n",
      "import matplotlib.pyplot as plt\n",
      "from analysis import viz\n",
      "from analysis import analyze as az\n",
      "\n",
      "#analysis\n",
      "import scipy.stats\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.cross_validation import cross_val_score \n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "import sklearn.metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir=os.getcwd()\n",
      "while 'Projects' in rootdir:\n",
      "    rootdir=os.path.dirname(rootdir)\n",
      "rootdir=os.path.join(rootdir, 'Projects','cragcrunch')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needsprep=True #do we need to do full preprocessing of the data or are we loading in a cleaned up dataset?\n",
      "dropfulls=True #if true, drop the full dataframes once we split into train and test (to save RAM)\n",
      "time2kill=True #run these only if we end up with time\n",
      "writedb=True #write dfs to sql database\n",
      "chunksize=1000 #chunk size when writing out large dataframes to sql\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "if needsprep:\n",
      "    #load in raw scraped data\n",
      "    con=MySQLdb.connect(user=cfg.user, passwd=cfg.passwd, db=cfg.dbname, host=cfg.host, charset=cfg.charset, use_unicode=cfg.charset)\n",
      "    full_climbdf = pd.read_sql(\"SELECT * from Climb\", con)\n",
      "    full_areadf = pd.read_sql(\"SELECT * from Area\", con)\n",
      "    full_climberdf = pd.read_sql(\"SELECT * from Climber\", con)\n",
      "    full_tickdf = pd.read_sql(\"SELECT * from Ticks\", con)\n",
      "    full_commentdf = pd.read_sql(\"SELECT * from Comments\", con)\n",
      "    full_gradedf = pd.read_sql(\"SELECT * from Grades\", con)\n",
      "    full_stardf = pd.read_sql(\"SELECT * from Stars\", con)\n",
      "    full_tododf = pd.read_sql(\"SELECT * from ToDos\", con)\n",
      "else:\n",
      "    #load in preprocessed data\n",
      "    engine = create_engine('mysql://%s@%s/%s?charset=%s&use_unicode=%s&passwd=%s' %(cfg.user, cfg.host, cfg.dbname, cfg.charset, cfg.use_unicode, cfg.passwd), pool_recycle=3600)\n",
      "    full_climbdf = pd.read_sql(\"SELECT * from climb_prepped\", engine, index_col='index')\n",
      "    full_areadf = pd.read_sql(\"SELECT * from area_prepped\", engine, index_col='index')\n",
      "    full_climberdf = pd.read_sql(\"SELECT * from climber_prepped\", engine, index_col='index')\n",
      "    full_tickdf = pd.read_sql(\"SELECT * from ticks_prepped\", engine, index_col='index')\n",
      "    full_commentdf = pd.read_sql(\"SELECT * from comments_prepped\", engine, index_col='index')\n",
      "    full_gradedf = pd.read_sql(\"SELECT * from grades_prepped\", engine, index_col='index')\n",
      "    full_stardf = pd.read_sql(\"SELECT * from stars_prepped\", engine, index_col='index')\n",
      "    full_tododf = pd.read_sql(\"SELECT * from todos_prepped\", engine, index_col='index')\n",
      "    full_hitsdf= pd.read_sql(\"SELECT * from hits_prepped\", engine, index_col='index')\n",
      "    mainareadf=pd.read_sql(\"SELECT * from mainarea_prepped\", engine, index_col='index')\n",
      "    climberxareadf=pd.read_sql(\"SELECT * from climberxareadf_prepped\", engine, index_col='index')\n",
      "    submittercounts=pd.read_sql(\"SELECT * from submittercounts_prepped\", engine, index_col='index')\n",
      "    diffdf=pd.read_sql(\"SELECT * from diffdf_prepped\", engine, index_col='index')\n",
      "    regioninfo=util.loadpickledobjects(os.path.join(rootdir, 'data', 'regioninfo.pkl'))[0]\n",
      "    terms=util.loadpickledobjects(os.path.join(rootdir, 'data', 'terms.pkl'))[0]\n",
      "    valenceterms=util.loadpickledobjects(os.path.join(rootdir, 'data', 'vterms.pkl'))[0]\n",
      "    datadicts=util.loadpickledobjects(os.path.join(rootdir, 'data', 'datadicts.pkl'))[0]\n",
      "    resultsdict=util.loadpickledobjects(os.path.join(rootdir, 'data', 'resultsdict.pkl'))[0]\n",
      "    testids=util.loadpickledobjects(os.path.join(rootdir, 'data', 'testids.pkl'))[0]\n",
      "    #rdf=util.loadpickledobjects(os.path.join(rootdir, 'data', 'rdf.pkl'))[0]\n",
      "    regions, regionids, regiondict=regioninfo['regions'], regioninfo['regionids'], regioninfo['regiondict']\n",
      "print \"data loaded\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "if needsprep:\n",
      "    #deal with duplicated areas and climbers\n",
      "    full_areadf=util.dedupareas(full_areadf) \n",
      "    full_climberdf=util.dedupclimbers(full_climberdf)\n",
      "    #some climber info missing from its dependent dfs, add climber data from climberdf\n",
      "    full_tickdf= util.addmissingclimbers(full_climberdf, full_tickdf)\n",
      "    full_commentdf = util.addmissingclimbers(full_climberdf, full_commentdf)\n",
      "    full_gradedf = util.addmissingclimbers(full_climberdf, full_gradedf)\n",
      "    full_tododf= util.addmissingclimbers(full_climberdf, full_tododf)\n",
      "    full_stardf = util.addmissingclimbers(full_climberdf, full_stardf)\n",
      "    #make single df of all climberxclimb interactions (of any kind: tick, star, grade, comment) (1 or 0 based on whether climber interacted with climb in any capacity)\n",
      "    full_hitsdf=pd.concat([full_tickdf[['climb','climber', 'urlname']],full_tododf[['climb','climber','urlname']],full_commentdf[['climb','climber','urlname']],full_gradedf[['climb','climber','urlname']]])\n",
      "    full_hitsdf=full_hitsdf[~full_hitsdf.duplicated()]\n",
      "    full_hitsdf=full_hitsdf.loc[~np.isnan(full_hitsdf.climber.values)]\n",
      "    #fix up some climber data errors\n",
      "    full_climberdf=util.fixclimbers(full_climberdf, full_hitsdf)\n",
      "    #reindex everything so that id is index\n",
      "    full_climbdf=util.reindex(full_climbdf)\n",
      "    full_areadf=util.reindex(full_areadf)\n",
      "    full_climberdf=util.reindex(full_climberdf)\n",
      "    full_tickdf=util.reindex(full_tickdf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_gradedf=util.reindex(full_gradedf)\n",
      "    full_stardf=util.reindex(full_stardf)\n",
      "    full_tododf=util.reindex(full_tododf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_stardf.starsscore=full_stardf.starsscore-1 #goofed up when extracting data and thought we were in a 1-5 system. actually in 0-4 where zero is \"danger\"/\"bomb\" rating\n",
      "    print \"performed initial preprocessing\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}