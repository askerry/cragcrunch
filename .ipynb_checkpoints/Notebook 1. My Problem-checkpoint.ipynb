{
 "metadata": {
  "name": "",
  "signature": "sha256:e3371a552542b4c932439b12afa58c957a3fabdfdf94b2272f993d3d757bb7b9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Day 1 of Insight Data Science: What is my problem?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Identifying the problem you want to solve, and the questions you need to answer to solve that problem, is one of the biggest challenges in data science. It won\u2019t matter how much data you have, how effectively you sanitized it, or whether you used the right machine learning algorithm-- if you aren\u2019t asking the right questions, or tackling the right problem, you are unlikely to achieve substantial gains from your data science project.\n",
      "\n",
      "The most appealing aspect of the Insight program is that I get to spend the majority of my time working on a data-related project of my choosing. I not only get to spend 6 weeks surrounded by smart, interesting people to learn from, but I also get to hack away on whatever problem I want!?! Awesome.\n",
      "\n",
      "So, what is my problem? The first day at Insight was largely devoted to this question.\n",
      "\n",
      "For this particular project, there are two types of factors to consider. 1) I want to find a project that I\u2019m passionate about, and for which there are insights or benefits to be gained from an extensive data investigation. 2) I want to choose a project that will challenge me, push me to expand my skillset, and provide a vehicle for communicating these skills to others (i.e. companies I want to work for).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. What problem do I want to solve?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rock climbing is one of my main passions. If I\u2019m not sitting at my computer, chances are I am some number of feet up a rock climbing wall. Conveniently, rock climbers are often data nerds. We like to document details about rock climbs all over the world, we tend to know what routes we\u2019ve climbed and when, and we tend to post this information on the web. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The problem:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a rock climber, there is nothing more exciting than planning a trip to a new climbing area. However, a given climbing area or national park often contains hundres or thousands of individual rock routes, and climbers will only tackle a handful of the routes on any given trip. Thus, climbers are often looking to find new climbing routes that they will enjoy and that will be appropriate for their skill level.\n",
      "\n",
      "The primary goal of CragCrunch is personalization. Every climber is [unique](http://climbingnarc.com/2012/01/defining-your-style/) and comes to the crag with their own skills, preferences, and goals. Similarly, every climb is different (e.g. different types of [holds](http://climbing.about.com/od/RockClimbingTechnique/tp/Nine-Basic-Types-Of-Climbing-Handholds.htm) and [faces](http://climbing.about.com/od/cliimbingtechniques/a/3RockFaces.htm)) and demands its own blend of mental and physical skills. CragCrunch aims to learn about its individual users to create a personalized system for finding climbs that are right for YOU. The key feature of this system is a [recommendation engine](http://en.wikipedia.org/wiki/Recommender_system) that makes personalized suggestions about climbs my model predicts you will enjoy. For users who have not built up an extensive climbing history, CragCrunch also provides for each climb suggestions of similar climbs. So look up a route you love and CragCrunch will suggest other climbs to add to your tick list. The climbing community helped to build this data source, so I want us to have the freedom to interact with the data to meet our individual goals and needs."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. What do I want to learn as a data scientist?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data science is the intersection of\n",
      "- statistics/machine learning\n",
      "- programming\n",
      "- data visualization\n",
      "- scientific hypothesis testing\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For me, #4 has been the bread and butter of my last ~8 years.  A science Ph.D. prepares you for data science in a number of ways, and I have some foundation in #1-#3 that I acquired as needed to answer scientific questions. But the data science industry is also different from Cognitive Neuroscience in a number of ways, and I have lots to learn to be able to tackle problems in industry. Here are a few of my learning goals for Insight, based on what I see as some of the largest disconnects between the kind of data analysis I\u2019ve done, and the kind of powers I\u2019ll need to have as a successful data scientist:\n",
      "- Data wrangling. (my data are images. I know exactly what they will look like and what kind of values they can take. there are some cleaning/preprocessing steps but they are fairly route)\n",
      "- Data scaling. (neuroscience data is not big data. I don\u2019t know or care exactly how much data constitutes big data, but I do know that we are far away from industry levels)\n",
      "- Rapid, iterative data exploration. (we often plan our analysis 100% ahead of time, and stick to the plan to avoid over-fitting/analysis holes)\n",
      "- Prediction and model evaluation. (Data scientists and scientists are often asking fundamentally different questions\u2026 trying to characterize a system vs. trying to make useful predictions).\n",
      "- Using models in \u201cproduction\u201d. (we get an \u201canswer\u201d, summarize it/visualize it, and present it in a paper)\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Project Proposal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A climbing recomendation system. Many climbers climb the same routes, and climbers often travel to different areas. Luckily, many climbers also record their climbing history on a website called www.mountainproject.com. If we can extract this user data we can, in principle, build a \"People who climbed this also liked...\"-style recommendation system. There are also objective variables (such as rock type, route length, and elevation) and more unstructured content (user-generated descriptions, comments) that could provide useful signals for identifying routes that are a good fit for a given individual. If we can harness this data (objective attributes, user-generated content, logs of which climbers have completed which routes, and whether they enjoyed them), we can build systems for characterizing different climbs and regions, and for providing personalized climbing recommendations.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Learning Goals\u2192 Project Components\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "1. data wrangling, cleaning, and sampling to get a suitable data set --> web scraping and extensive wrangling of user-entered data from web resource\n",
      "1. data management to be able to access big data quickly and reliably --> transforming scraped data into structured schemas (saved as a relational database, manipulated as pandas dataframes), use of dimensionality reduction (feature selection) and parallelization to speed up processing\n",
      "1. exploratory data analysis to generate hypotheses and intuition -->exploratory visualization of plausible predictors and relationships\n",
      "1. prediction based on statistical methods such as regression and classification --> classification of global climb popularity and individual user preferences\n",
      "1. communication of results through visualization and interpretable summaries -->visualization of statistical results, as well as visualization of user-oriented information\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tools"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "My analyses relied heavily on the following python libraries:\n",
      "\n",
      "1. [Scrapy](http://scrapy.org/) for web scraping\n",
      "2. [Sqlalchemy](http://www.sqlalchemy.org/) for converting scraped data classes into a set of relational database schemas (MySQL)\n",
      "3. [Pandas](http://pandas.pydata.org/) for online data representation and transformation\n",
      "4. [Scipy](http://www.scipy.org/scipylib/index.html) and [Statsmodels](http://statsmodels.sourceforge.net/) for inferential statistics\n",
      "5. [Sci-kit learn](http://scikit-learn.org/stable/) for building models (constructing cross-validation procedures, performing feature selection, fitting model parameters, testing trained models)\n",
      "6. [Matplotlib](http://matplotlib.org/) and [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) for visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}