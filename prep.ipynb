{
 "metadata": {
  "name": "",
  "signature": "sha256:6eadebb2fabfc62c44e48753658983767640da2cc38db84bdd515ef4a2ac3ab3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "#basic\n",
      "import pandas as pd\n",
      "pd.options.mode.chained_assignment = 'warn'  # default='warn', None, 'raise'\n",
      "#pd.options.display.memory_usage = True\n",
      "import numpy as np\n",
      "np.random.RandomState(100)\n",
      "import MySQLdb\n",
      "from sqlalchemy import create_engine\n",
      "import os\n",
      "import sys\n",
      "sys.setrecursionlimit(3000)\n",
      "from joblib import Parallel, delayed  \n",
      "import multiprocessing\n",
      "num_cores = multiprocessing.cpu_count()\n",
      "print \"%s cores available for parallel processing\" % num_cores\n",
      "import sys, os\n",
      "\n",
      "\n",
      "#interaction\n",
      "from IPython.html import widgets # Widget definitions\n",
      "from IPython.display import display # Used to display widgets in the notebook\n",
      "\n",
      "#specific\n",
      "sys.path.append('mpscraper')\n",
      "sys.path.append('analysis')\n",
      "from mpscraper.cfgdb import cfg\n",
      "import analysis.utilities as util\n",
      "from analysis.analyze import modeldict\n",
      "from analysis.domainvariables import states, grades, rawgrades, bouldergrades, holdterms, rockterms, descriptors, easeterms, safetyterms\n",
      "#viz\n",
      "import seaborn as sns\n",
      "sns.set_style('white')\n",
      "import matplotlib.pyplot as plt\n",
      "from analysis import viz\n",
      "from analysis import analyze as az\n",
      "\n",
      "#analysis\n",
      "import scipy.stats\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.cross_validation import cross_val_score \n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "import sklearn.metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4 cores available for parallel processing\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%autoreload` not found.\n"
       ]
      },
      {
       "ename": "ImportError",
       "evalue": "No module named analysis.utilities",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-a73e90b0dbb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfgdb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodeldict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomainvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrades\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawgrades\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbouldergrades\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrockterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0measeterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafetyterms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named analysis.utilities"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir=os.getcwd()\n",
      "while 'Projects' in rootdir:\n",
      "    rootdir=os.path.dirname(rootdir)\n",
      "rootdir=os.path.join(rootdir, 'Projects','cragcrunch')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dropfulls=True #if true, drop the full dataframes once we split into train and test (to save RAM)\n",
      "writedb=True #write dfs to sql database\n",
      "chunksize=1000 #chunk size when writing out large dataframes to sql\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "\n",
      "#load in raw scraped data\n",
      "con=MySQLdb.connect(user=cfg.user, passwd=cfg.passwd, db=cfg.dbname, host=cfg.host, charset=cfg.charset, use_unicode=cfg.charset)\n",
      "full_climbdf = pd.read_sql(\"SELECT * from Climb\", con)\n",
      "full_areadf = pd.read_sql(\"SELECT * from Area\", con)\n",
      "full_climberdf = pd.read_sql(\"SELECT * from Climber\", con)\n",
      "full_tickdf = pd.read_sql(\"SELECT * from Ticks\", con)\n",
      "full_commentdf = pd.read_sql(\"SELECT * from Comments\", con)\n",
      "full_gradedf = pd.read_sql(\"SELECT * from Grades\", con)\n",
      "full_stardf = pd.read_sql(\"SELECT * from Stars\", con)\n",
      "full_tododf = pd.read_sql(\"SELECT * from ToDos\", con)\n",
      "print \"data loaded\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bulk of cleaning performed online during scraping process, but I didn't get everything right\n",
      "#so, some additional data cleaning needs to be performed post acquisition \n",
      "full_climbdf=full_climbdf[['name']+[el for el in full_climbdf.columns.tolist() if el!='name']] #moving name first\n",
      "#cleandf makes sure columns are of the right datatype, strips empty spaces from ends of strings, cleans up missing values, etc.\n",
      "full_climbdf=util.cleandf(full_climbdf)\n",
      "full_areadf=util.cleandf(full_areadf) \n",
      "full_climberdf=util.cleandf(full_climberdf) \n",
      "full_tickdf=util.cleandf(full_tickdf) \n",
      "full_commentdf=util.cleandf(full_commentdf) \n",
      "full_gradedf=util.cleandf(full_gradedf) \n",
      "full_stardf=util.cleandf(full_stardf) \n",
      "full_tododf=util.cleandf(full_tododf) \n",
      "print \"performed initial cleaning\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we are focusing on rock climbing and will drop alpine/ice climbing data from the dataset\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.dropstyles(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "#we also limit to climbs in the USA only    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "if needsprep:\n",
      "    #deal with duplicated areas and climbers\n",
      "    full_areadf=util.dedupareas(full_areadf) \n",
      "    full_climberdf=util.dedupclimbers(full_climberdf)\n",
      "    #some climber info missing from its dependent dfs, add climber data from climberdf\n",
      "    full_tickdf= util.addmissingclimbers(full_climberdf, full_tickdf)\n",
      "    full_commentdf = util.addmissingclimbers(full_climberdf, full_commentdf)\n",
      "    full_gradedf = util.addmissingclimbers(full_climberdf, full_gradedf)\n",
      "    full_tododf= util.addmissingclimbers(full_climberdf, full_tododf)\n",
      "    full_stardf = util.addmissingclimbers(full_climberdf, full_stardf)\n",
      "    #make single df of all climberxclimb interactions (of any kind: tick, star, grade, comment) (1 or 0 based on whether climber interacted with climb in any capacity)\n",
      "    full_hitsdf=pd.concat([full_tickdf[['climb','climber', 'urlname']],full_tododf[['climb','climber','urlname']],full_commentdf[['climb','climber','urlname']],full_gradedf[['climb','climber','urlname']]])\n",
      "    full_hitsdf=full_hitsdf[~full_hitsdf.duplicated()]\n",
      "    full_hitsdf=full_hitsdf.loc[~np.isnan(full_hitsdf.climber.values)]\n",
      "    #fix up some climber data errors\n",
      "    full_climberdf=util.fixclimbers(full_climberdf, full_hitsdf)\n",
      "    #reindex everything so that id is index\n",
      "    full_climbdf=util.reindex(full_climbdf)\n",
      "    full_areadf=util.reindex(full_areadf)\n",
      "    full_climberdf=util.reindex(full_climberdf)\n",
      "    full_tickdf=util.reindex(full_tickdf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_gradedf=util.reindex(full_gradedf)\n",
      "    full_stardf=util.reindex(full_stardf)\n",
      "    full_tododf=util.reindex(full_tododf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_commentdf=util.reindex(full_commentdf)\n",
      "    full_stardf.starsscore=full_stardf.starsscore-1 #goofed up when extracting data and thought we were in a 1-5 system. actually in 0-4 where zero is \"danger\"/\"bomb\" rating\n",
      "    print \"performed initial preprocessing\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}