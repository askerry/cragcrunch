{
 "metadata": {
  "name": "",
  "signature": "sha256:ca46d02c16fddd8d09a86ae0d8fb25d2bb70c5eaf08454c86fe460fd21d9cf0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing scraped data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A fair amount of data cleaning was performed online during the scraping process. However, the data stored in the initial database is still rather messy and there is work to be done  post acquisition. Here, I implement further cleaning/wrangling to get the data in shape for modeling and visualization."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#general\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "np.random.RandomState(100)\n",
      "from sqlalchemy import create_engine\n",
      "import MySQLdb\n",
      "import os\n",
      "import sys\n",
      "sys.setrecursionlimit(3000)\n",
      "\n",
      "#project specific code\n",
      "sys.path.append('mpscraper')\n",
      "sys.path.append('antools')\n",
      "from mpscraper.cfgdb import cfg\n",
      "import antools.random as rd\n",
      "import antools.utilities as util\n",
      "import antools.clean as clean\n",
      "import antools.reduction as red\n",
      "import antools.miscdf as miscdf\n",
      "import antools.climbingcalcs as ccc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir=os.getcwd()\n",
      "while 'Projects' in rootdir:\n",
      "    rootdir=os.path.dirname(rootdir)\n",
      "rootdir=os.path.join(rootdir, 'Projects','cragcrunch')\n",
      "dropfulls=True #if true, drop the full dataframes once we split into train and test (to save RAM)\n",
      "writedb=True #write dfs to sql database\n",
      "chunksize=1000 #chunk size when writing out large dataframes to sql\n",
      "terms=rd.rockterms+rd.holdterms+rd.descriptors+rd.easeterms+rd.safetyterms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load in raw scraped data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "con=MySQLdb.connect(user=cfg.user, passwd=cfg.passwd, db=cfg.dbname, host=cfg.host, charset=cfg.charset, use_unicode=cfg.charset)\n",
      "full_climbdf = pd.read_sql(\"SELECT * from Climb\", con)\n",
      "full_climbdf=full_climbdf[['name']+[el for el in full_climbdf.columns.tolist() if el!='name']] #moving name first\n",
      "full_areadf = pd.read_sql(\"SELECT * from Area\", con)\n",
      "full_climberdf = pd.read_sql(\"SELECT * from Climber\", con)\n",
      "full_tickdf = pd.read_sql(\"SELECT * from Ticks\", con)\n",
      "full_commentdf = pd.read_sql(\"SELECT * from Comments\", con)\n",
      "full_gradedf = pd.read_sql(\"SELECT * from Grades\", con)\n",
      "full_stardf = pd.read_sql(\"SELECT * from Stars\", con)\n",
      "full_tododf = pd.read_sql(\"SELECT * from ToDos\", con)\n",
      "print \"data loaded\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data loaded\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clean up individual attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "#cleandf makes sure columns are of the right datatype, strips empty spaces from ends of strings, cleans up missing values, etc.\n",
      "full_climbdf=util.cleandf(full_climbdf)\n",
      "full_areadf=util.cleandf(full_areadf) \n",
      "full_climberdf=util.cleandf(full_climberdf) \n",
      "full_tickdf=util.cleandf(full_tickdf) \n",
      "full_commentdf=util.cleandf(full_commentdf) \n",
      "full_gradedf=util.cleandf(full_gradedf) \n",
      "full_stardf=util.cleandf(full_stardf) \n",
      "full_tododf=util.cleandf(full_tododf) \n",
      "print \"performed dataframe initial cleaning\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed dataframe initial cleaning\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climb styles that fall outside scope of the project"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we are focusing on rock climbing and will drop alpine/ice climbing data from the dataset\n",
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropstyles(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"dropped types of climbs we don't care about\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped types of climbs we don't care about\n",
        "starting with 121849, reducing to 118539\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas in the USA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf, full_areadf=red.limittoUSA(full_climbdf, full_areadf)\n",
      "print \"limited to USA\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))\n",
      "print \"starting with %s, reducing to %s\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "limited to USA\n",
        "starting with 26703, reducing to 21106\n",
        "starting with 118539, reducing to 110317\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Align location information and drops climbs that are missing location info"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf=pd.merge(full_climbdf, full_areadf[['areaid','region']], left_on='area', right_on='areaid', how='inner')\n",
      "full_climbdf=full_climbdf.rename(columns={'region_y':'region'})\n",
      "print \"added regions to climbs and dropped climbs missing areas\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "added regions to climbs and dropped climbs missing areas\n",
        "starting with 110317, reducing to 92511\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climbs that we don't have grade information for\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropungraded(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting with 92511, reducing to 92511\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Removing duplicates, fixing missing values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.dedupsandmissing(full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"performed deduping, filled in missing values\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed deduping, filled in missing values\n",
        "starting with 21106, reducing to 21005\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Climber x Climb Matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make single df of all climberxclimb interactions (of any kind: tick, star, grade, comment) (1 or 0 based on whether climber interacted with climb in any capacity)\n",
      "full_hitsdf=pd.concat([full_tickdf[['climb','climber', 'urlname']],full_tododf[['climb','climber','urlname']],full_commentdf[['climb','climber','urlname']],full_gradedf[['climb','climber','urlname']]])\n",
      "full_hitsdf=full_hitsdf[~full_hitsdf.duplicated()]\n",
      "full_hitsdf=full_hitsdf.loc[~np.isnan(full_hitsdf.climber.values)]\n",
      "print \"created full climber x climber matrix\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "created full climber x climber matrix\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Misc fixes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fix up some climber data errors\n",
      "full_climberdf=clean.fixclimbers(full_climberdf, full_hitsdf)\n",
      "\"fixed duped climbers\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'fixed duped climbers'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reindex everything so that id is index\n",
      "full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.reindexall(full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"reindexed dataframes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reindexed dataframes\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#goofed up when extracting data and thought we were in a 1-5 system. actually in 0-4 where zero is \"danger\"/\"bomb\" rating\n",
      "#random cleanup hacks\n",
      "full_stardf.starsscore=full_stardf.starsscore-1\n",
      "full_climberdf.loc[full_climberdf['age']>120, 'age']=np.nan\n",
      "print \"performed random cleanup hacks\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed random cleanup hacks\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convert grade to a linear scale"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf['numerizedgrade']=full_climbdf['grade'].apply(clean.numerizegrades, gradelists=[rd.grades, rd.bouldergrades])\n",
      "full_climbdf['numgrade']=full_climbdf['grade'].apply(clean.splitgrade, output='num')\n",
      "full_climbdf['lettergrade']=full_climbdf['grade'].apply(clean.splitgrade, output='letter')\n",
      "print \"redefined grading\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "redefined grading\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find main parks/areas for climbs and climbers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "states, stateids, statedict, mainareadf, full_areadf, full_climbdf=ccc.getstatesandmainareas(full_areadf, full_climbdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified main areas/parks for subareas\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climberdf)\n",
      "#because we dropped non-USA and certain forms of climbers, there are users for which we have no climbing history. drop them.\n",
      "full_climberdf=full_climberdf[full_climberdf['climberid'].isin(full_hitsdf.climber.values)]\n",
      "print \"dropping climbers for which we have no climbing history\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climberdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping climbers for which we have no climbing history\n",
        "starting with 5685, reducing to 1545\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climberdf=ccc.getclimberareas(full_hitsdf, full_climbdf, full_climberdf) #note this uses whole dataset, shouldn't be part of any training/testing\n",
      "print \"identified climber mainareas\"   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified climber mainareas\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getregion(mid, areadf):\n",
      "    return areadf[areadf['areaid']==mid].region.values[0]\n",
      "full_climberdf['region']=full_climberdf['mainarea'].apply(getregion, areadf=full_areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract counts for a priori terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract word counts for a priori terms from comments and descriptions\n",
      "print \"merging climb comments\"\n",
      "full_climbdf=miscdf.mergeclimbcomment(full_commentdf, full_climbdf)\n",
      "print \"making descripdf\"\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['description']) #'commentsmerged'\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['commentsmerged'])\n",
      "print \"finished descripdf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging climb comments\n",
        "making descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "finished descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fixing up star data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_climbdf=clean.fixstars(full_stardf, full_climbdf)\n",
      "print \"fixed stars\"\n",
      "full_climbdf=miscdf.combinestars(full_climbdf)\n",
      "print \"combined stars\"\n",
      "full_climbdf['roundedstars']=full_climbdf['avgstars'].apply(np.round) \n",
      "#stardf=getrelativestar(stardf,climbdf)\n",
      "#gradedf=computerelativegrades(climbdf, gradedf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fixed stars\n",
        "combined stars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Deal with variability in grading standards across regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print \"computing grade variability\"\n",
      "#climbdf=computegradevariability(climbdf, gradedf)\n",
      "#climbdf=computeclimbstiffness(climbdf, gradedf, climberdf)\n",
      "#print \"finished grade stiffness\"\n",
      "#areadf=computeareastiffness(climbdf, areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#submittercounts=summarizesubmitters(climbdf, climberdf, hitsdf) #note this uses whole dataset, shouldn't be part of any training/testing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas for which we have some user data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf=full_climbdf[full_climbdf['climbid'].isin(full_hitsdf.climb.values)]\n",
      "areas=list(full_climbdf.area.unique())+list(full_areadf.area.unique())\n",
      "full_areadf=full_areadf[full_areadf['areaid'].isin(areas)]\n",
      "print \"dropped climbs with no user data\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))\n",
      "print \"starting with %s, reducing to %s\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped climbs with no user data\n",
        "starting with 21005, reducing to 11937\n",
        "starting with 92511, reducing to 41561\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Write preprocessed data to database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if writedb:\n",
      "    #save prepped data to sql\n",
      "    engine = create_engine('mysql://%s@%s/%s?charset=%s&use_unicode=%s&passwd=%s' %(cfg.user, cfg.host, cfg.dbname, cfg.charset, cfg.use_unicode, cfg.passwd), pool_recycle=3600)\n",
      "    full_climbdf.to_sql('climb_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_areadf.to_sql('area_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_climberdf.to_sql('climber_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tickdf.to_sql('ticks_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_commentdf.to_sql('comments_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_gradedf.to_sql('grades_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_stardf.to_sql('stars_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tododf.to_sql('todos_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_hitsdf.to_sql('hits_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    #regioninfo={'regions':regions, 'regionids':regionids, 'regiondict':regiondict}\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'regioninfo.pkl'), [regioninfo])\n",
      "    util.pickletheseobjects(os.path.join(rootdir, 'data', 'terms.pkl'),[terms])\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'vterms.pkl'),[valenceterms])\n",
      "    mainareadf.to_sql('mainarea_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    climberxareadf.to_sql('climberxareadf_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    #submittercounts.to_sql('submittercounts_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    print \"wrote to db\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OperationalError",
       "evalue": "(OperationalError) (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\") None None",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-27-28509d1615fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#save prepped data to sql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mysql://%s@%s/%s?charset=%s&use_unicode=%s&passwd=%s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_unicode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasswd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_recycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfull_climbdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'climb_prepped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfull_areadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'area_prepped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfull_climberdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'climber_prepped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize)\u001b[0m\n\u001b[1;32m    954\u001b[0m         sql.to_sql(\n\u001b[1;32m    955\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             index=index, index_label=index_label, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize)\u001b[0m\n\u001b[1;32m    532\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[1;32m    533\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                       chunksize=chunksize)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize)\u001b[0m\n\u001b[1;32m   1131\u001b[0m                          \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                          schema=schema)\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# check for potentially case sensitivity issues (GH7815)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table '%s' already exists.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msql_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mhas_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mhas_table\u001b[0;34m(self, table_name, schema)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \"\"\"\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mrun_callable\u001b[0;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \"\"\"\n\u001b[0;32m-> 1662\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mcontextual_connect\u001b[0;34m(self, close_with_result, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m         return self._connection_cls(self,\n\u001b[0;32m-> 1729\u001b[0;31m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m                                     \u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                                     **kwargs)\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_threadlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m_checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_checkout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadconns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mfairy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mfairy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36mcheckout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mdbapi_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m_do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inc_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dec_overflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;34m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_invalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/pool.pyc\u001b[0m in \u001b[0;36m__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created new connection %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/strategies.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m                         exc.DBAPIError.instance(None, None,\n\u001b[1;32m     94\u001b[0m                             \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                             \u001b[0mconnection_invalidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minvalidated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                         )\n\u001b[1;32m     97\u001b[0m                     )\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/util/compat.pyc\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/strategies.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0minvalidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_disconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_connect_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/MySQLdb/__init__.pyc\u001b[0m in \u001b[0;36mConnect\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;34m\"\"\"Factory function for connections.Connection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mconnect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/MySQLdb/connections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mautocommit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autocommit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursorclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursorclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         self.encoders = dict([ (k, v) for k, v in conv.items()\n",
        "\u001b[0;31mOperationalError\u001b[0m: (OperationalError) (2002, \"Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\") None None"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}