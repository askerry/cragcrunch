{
 "metadata": {
  "name": "",
  "signature": "sha256:556ef26c60911a17524314d059991b0b201b643184d549d0e97a4ad51178fe22"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing scraped data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A fair amount of data cleaning was performed online during the scraping process. However, the data stored in the initial database is still rather messy and there is work to be done  post acquisition. Here, I implement further cleaning/wrangling to get the data in shape for modeling and visualization."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#general\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "np.random.RandomState(100)\n",
      "from sqlalchemy import create_engine\n",
      "import MySQLdb\n",
      "import os\n",
      "import sys\n",
      "sys.setrecursionlimit(3000)\n",
      "\n",
      "#project specific code\n",
      "sys.path.append('mpscraper')\n",
      "sys.path.append('antools')\n",
      "from mpscraper.cfgdb import cfg\n",
      "import antools.random as rd\n",
      "import antools.utilities as util\n",
      "import antools.clean as clean\n",
      "import antools.reduction as red\n",
      "import antools.miscdf as miscdf\n",
      "import antools.climbingcalcs as ccc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir=os.getcwd()\n",
      "while 'Projects' in rootdir:\n",
      "    rootdir=os.path.dirname(rootdir)\n",
      "rootdir=os.path.join(rootdir, 'Projects','cragcrunch')\n",
      "dropfulls=True #if true, drop the full dataframes once we split into train and test (to save RAM)\n",
      "writedb=True #write dfs to sql database\n",
      "chunksize=1000 #chunk size when writing out large dataframes to sql\n",
      "terms=rd.rockterms+rd.holdterms+rd.descriptors+rd.easeterms+rd.safetyterms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load in raw scraped data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "con=MySQLdb.connect(user=cfg.user, passwd=cfg.passwd, db=cfg.dbname, host=cfg.host, charset=cfg.charset, use_unicode=cfg.charset)\n",
      "full_climbdf = pd.read_sql(\"SELECT * from Climb\", con)\n",
      "full_climbdf=full_climbdf[['name']+[el for el in full_climbdf.columns.tolist() if el!='name']] #moving name first\n",
      "full_areadf = pd.read_sql(\"SELECT * from Area\", con)\n",
      "full_climberdf = pd.read_sql(\"SELECT * from Climber\", con)\n",
      "full_tickdf = pd.read_sql(\"SELECT * from Ticks\", con)\n",
      "full_commentdf = pd.read_sql(\"SELECT * from Comments\", con)\n",
      "full_gradedf = pd.read_sql(\"SELECT * from Grades\", con)\n",
      "full_stardf = pd.read_sql(\"SELECT * from Stars\", con)\n",
      "full_tododf = pd.read_sql(\"SELECT * from ToDos\", con)\n",
      "print \"data loaded\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data loaded\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Clean up individual attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "#cleandf makes sure columns are of the right datatype, strips empty spaces from ends of strings, cleans up missing values, etc.\n",
      "full_climbdf=util.cleandf(full_climbdf)\n",
      "full_areadf=util.cleandf(full_areadf) \n",
      "full_climberdf=util.cleandf(full_climberdf) \n",
      "full_tickdf=util.cleandf(full_tickdf) \n",
      "full_commentdf=util.cleandf(full_commentdf) \n",
      "full_gradedf=util.cleandf(full_gradedf) \n",
      "full_stardf=util.cleandf(full_stardf) \n",
      "full_tododf=util.cleandf(full_tododf) \n",
      "print \"performed dataframe initial cleaning\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed dataframe initial cleaning\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climb styles that fall outside scope of the project"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we are focusing on rock climbing and will drop alpine/ice climbing data from the dataset\n",
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropstyles(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"dropped types of climbs we don't care about\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped types of climbs we don't care about\n",
        "starting with 121849, reducing to 118539\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas in the USA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf, full_areadf=red.limittoUSA(full_climbdf, full_areadf)\n",
      "print \"limited to USA\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))\n",
      "print \"starting with %s, reducing to %s\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "limited to USA\n",
        "starting with 26703, reducing to 21106\n",
        "starting with 118539, reducing to 110317\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Align location information and drop climbs that are missing location info"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf=pd.merge(full_climbdf, full_areadf[['areaid','region']], left_on='area', right_on='areaid', how='inner')\n",
      "full_climbdf=full_climbdf.rename(columns={'region_y':'region'})\n",
      "print \"added regions to climbs and dropped climbs missing areas\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "added regions to climbs and dropped climbs missing areas\n",
        "starting with 110317, reducing to 92511\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drop climbs for which we don't have grade information\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climbdf)\n",
      "full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=red.dropungraded(full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting with 92511, reducing to 92511\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Removing duplicates, fixing missing values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.dedupsandmissing(full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"performed deduping, filled in missing values\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_areadf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed deduping, filled in missing values\n",
        "starting with 21106, reducing to 21005\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Climber x Climb Matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make single df of all climberxclimb interactions (of any kind: tick, star, grade, comment) (1 or 0 based on whether climber interacted with climb in any capacity)\n",
      "full_hitsdf=pd.concat([full_tickdf[['climb','climber', 'urlname']],full_tododf[['climb','climber','urlname']],full_commentdf[['climb','climber','urlname']],full_gradedf[['climb','climber','urlname']]])\n",
      "full_hitsdf=full_hitsdf[~full_hitsdf.duplicated()]\n",
      "full_hitsdf=full_hitsdf.loc[~np.isnan(full_hitsdf.climber.values)]\n",
      "full_hitsdf.index=range(len(full_hitsdf))\n",
      "full_hitsdf['hitsid']=full_hitsdf.index.values\n",
      "print \"created full climber x climb matrix\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "created full climber x climb matrix\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Misc fixes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fix up some climber data errors\n",
      "full_climberdf=clean.fixclimbers(full_climberdf, full_hitsdf)\n",
      "\"fixed duped climbers\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "'fixed duped climbers'"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reindex everything so that id is index\n",
      "%autoreload\n",
      "full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf=util.reindexall(full_hitsdf,full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf)\n",
      "print \"reindexed dataframes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reindexed dataframes\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#goofed up when extracting data and thought we were in a 1-5 system. actually in 0-4 where zero is \"danger\"/\"bomb\" rating\n",
      "#random cleanup hacks\n",
      "full_stardf.starsscore=full_stardf.starsscore-1\n",
      "full_climberdf.loc[full_climberdf['age']>120, 'age']=np.nan\n",
      "print \"performed random cleanup hacks\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "performed random cleanup hacks\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convert grade to a linear scale"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf['numerizedgrade']=full_climbdf['grade'].apply(clean.numerizegrades, gradelists=[rd.grades, rd.bouldergrades])\n",
      "full_climbdf['numgrade']=full_climbdf['grade'].apply(clean.splitgrade, output='num')\n",
      "full_climbdf['lettergrade']=full_climbdf['grade'].apply(clean.splitgrade, output='letter')\n",
      "print \"redefined grading\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "redefined grading\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find main parks/areas for climbs and climbers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "states, stateids, statedict, mainareadf, full_areadf, full_climbdf=ccc.getstatesandmainareas(full_areadf, full_climbdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified main areas/parks for subareas\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_climberdf)\n",
      "#because we dropped non-USA and certain forms of climbers, there are users for which we have no climbing history. drop them.\n",
      "full_climberdf=full_climberdf[full_climberdf['climberid'].isin(full_hitsdf.climber.values)]\n",
      "print \"dropping climbers for which we have no climbing history\"\n",
      "print \"starting with %s, reducing to %s\" %(i, len(full_climberdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping climbers for which we have no climbing history\n",
        "starting with 366, reducing to 366\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climberdf=ccc.getclimberareas(full_hitsdf, full_climbdf, full_climberdf) #note this uses whole dataset, shouldn't be part of any training/testing\n",
      "print \"identified climber mainareas\"   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "identified climber mainareas\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getregion(mid, areadf):\n",
      "    return areadf[areadf['areaid']==mid].region.values[0]\n",
      "full_climberdf['region']=full_climberdf['mainarea'].apply(getregion, areadf=full_areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract counts for a priori terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#extract word counts for a priori terms from comments and descriptions\n",
      "print \"merging climb comments\"\n",
      "full_climbdf=miscdf.mergeclimbcomment(full_commentdf, full_climbdf)\n",
      "print \"making descripdf\"\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['description']) #'commentsmerged'\n",
      "full_climbdf=miscdf.makedescripdf(full_climbdf, terms, ['commentsmerged'])\n",
      "print \"finished descripdf\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging climb comments\n",
        "making descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "finished descripdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fixing up star data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_climbdf=clean.fixstars(full_stardf, full_climbdf)\n",
      "print \"fixed stars\"\n",
      "full_climbdf=miscdf.combinestars(full_climbdf)\n",
      "print \"combined stars\"\n",
      "full_climbdf['roundedstars']=full_climbdf['avgstars'].apply(np.round) \n",
      "stardf=ccc.computerelativestar(full_stardf,full_climbdf)\n",
      "print \"computed relative stars\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fixed stars\n",
        "combined stars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "computed relative stars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get relative grade"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_gradedf=ccc.computerelativegrades(full_climbdf, full_gradedf)\n",
      "print \"computed relative grades\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "computed relative grades\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Deal with variability in grading standards across regions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##NVM this is actually really hard. hold off.\n",
      "#print \"computing grade variability\"\n",
      "#climbdf=computegradevariability(climbdf, gradedf)\n",
      "#climbdf=computeclimbstiffness(climbdf, gradedf, climberdf)\n",
      "#print \"finished grade stiffness\"\n",
      "#areadf=computeareastiffness(climbdf, areadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#submittercounts=summarizesubmitters(climbdf, climberdf, hitsdf) #note this uses whole dataset, shouldn't be part of any training/testing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Limit to climbs and areas for which we have some user data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=len(full_areadf)\n",
      "j=len(full_climbdf)\n",
      "full_climbdf=full_climbdf[full_climbdf['climbid'].isin(full_hitsdf.climb.values)]\n",
      "areas=list(full_climbdf.area.unique())+list(full_areadf.area.unique())\n",
      "full_areadf=full_areadf[full_areadf['areaid'].isin(areas)]\n",
      "print \"dropped climbs with no user data\"\n",
      "print \"starting with %s areas, reducing to %s areas\" %(i, len(full_areadf))\n",
      "print \"starting with %s climbs, reducing to %s climbs\" %(j, len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropped climbs with no user data\n",
        "starting with 4873 areas, reducing to 3623 areas\n",
        "starting with 9617 climbs, reducing to 9617 climbs\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "For now let's limit the product to climbs in California and New Hampshire"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_climbdf=full_climbdf[full_climbdf['region'].isin(['California','New Hampshire'])]\n",
      "print \"reducing to %s climbs\" %(len(full_climbdf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reducing to 9617 climbs\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload\n",
      "full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf=red.dropclimbs(full_climbdf, full_hitsdf, full_stardf, full_commentdf, full_gradedf, full_tickdf)\n",
      "full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf, mainareadf=util.renameindices(full_hitsdf, full_climberdf, full_areadf, full_climbdf,full_stardf,full_commentdf,full_gradedf,full_tickdf,full_tododf, mainareadf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Write preprocessed data to database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if writedb:\n",
      "    #save prepped data to sql\n",
      "    engine = create_engine('mysql://%s@%s/%s?charset=%s&use_unicode=%s&passwd=%s' %(cfg.user, cfg.host, cfg.dbname, cfg.charset, cfg.use_unicode, cfg.passwd), pool_recycle=3600)\n",
      "    full_areadf.to_sql('area_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_climberdf.to_sql('climber_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tickdf.to_sql('ticks_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_commentdf.to_sql('comments_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_gradedf.to_sql('grades_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_stardf.to_sql('stars_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_tododf.to_sql('todos_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_hitsdf.to_sql('hits_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    full_climbdf.to_sql('climb_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    #regioninfo={'regions':regions, 'regionids':regionids, 'regiondict':regiondict}\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'regioninfo.pkl'), [regioninfo])\n",
      "    util.pickletheseobjects(os.path.join(rootdir, 'data', 'terms.pkl'),[terms])\n",
      "    #util.pickletheseobjects(os.path.join(rootdir, 'data', 'vterms.pkl'),[valenceterms])\n",
      "    mainareadf.to_sql('mainarea_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    #climberxareadf.to_sql('climberxareadf_prepped', engine, engine, if_exists='replace', chunksize=chunksize)\n",
      "    #submittercounts.to_sql('submittercounts_prepped', engine, if_exists='replace', chunksize=chunksize)\n",
      "    print \"wrote to db\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wrote to db\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}